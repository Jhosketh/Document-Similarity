tdm
cosine_dist_mat_v1 <- crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
cosine_dist_mat_v1
unlink(".RData")
corpus
# COSINE SIMILARITY
require("tm")
require("SnowballC")
library(slam)
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm <- TermDocumentMatrix(corpus)
tdm
inspect(tdm)
cosine_dist_mat_v1 <- crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
cosine_dist_mat_v1
weightbBin(tdm)
weightBin(tdm)
cosine_dist_mat_v1 <- crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
cosine_dist_mat_v1
inspect(tdm)
m <- as.matrix(tdm)
m
cosine_dist_mat_v1 <- crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))
cosine_dist_mat_v1
tdm
weightBin(tdm)
tdm
tdm.bin <- weightBin(tdm)
tdm.bin
cosine_dist_mat_v1 <- crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2cosine_dist_mat_v1 <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))))))
cosine_dist_mat_v1 <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine_dist_mat_v1
tdm.bin <- TermDocumentMatrix(corpus, weighting = weightBin)
tdm.bin <- TermDocumentMatrix(corpus, weighting = "weightBin")
freq <- colSums(as.matrix(dtms))   
dtm <- DocumentTermMatrix(corpus)
inspect(dtm)
dtms <- removeSparseTerms(dtm, 0.1)    
inspect(dtms)
freq <- colSums(as.matrix(dtms))   
freq
freq <- colSums(as.matrix(dtm))   
freq
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)   
head(freq, 14)   
findFreqTerms(dtm, lowfreq=50)
findFreqTerms(dtm, lowfreq=1)
findFreqTerms(dtm, lowfreq=5)
wf <- data.frame(word=names(freq), freq=freq)   
wf
wf <- data.frame(word=names(freq), freq=freq)   
head(wf)  
library(ggplot2)   
p <- ggplot(subset(wf, freq>50), aes(word, freq))    
p <- p + geom_bar(stat="identity")   
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))   
p
p <- ggplot(subset(wf, freq>50), aes(word, freq))    
# Plot Word Frequencies
library(ggplot2)   
p <- ggplot(subset(wf, freq>2), aes(word, freq))    
p <- p + geom_bar(stat="identity")   
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))   
p
library(wordcloud)   
# Wordcloud
library(wordcloud)   
set.seed(142)   
wordcloud(names(freq), freq, min.freq=25)
# Wordcloud
library(wordcloud)   
set.seed(142)   
wordcloud(names(freq), freq, min.freq=50)
# Wordcloud
library(wordcloud)   
set.seed(142)   
wordcloud(names(freq), freq, min.freq=25)
# COSINE SIMILARITY
require("tm")
require("SnowballC")
library(slam)
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
cosine.dist.bin 
cosine.dist.tf
cosine.dist.tfidf 
# COSINE SIMILARITY
require("tm")
require("SnowballC")
library(slam)
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
write.csv(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.csv(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary", append=TRUE)
write.csv(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.csv(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tfidf", append=TRUE)
write.csv(m.vector.space, file="doc_sim.csv", sheetName="vector_space")
write.csv(m.bin, file="doc_sim.csv", sheetName="cosine_binary", append=TRUE)
write.csv(m.tf, file="doc_sim.csv", sheetName="cosine_tf", append=TRUE)
write.csv(m.tfidf, file="doc_sim.csv", sheetName="cosine_tfidf", append=TRUE)
write.csv(m.vector.space, file="doc_sim.csv", sheetName="vector_space")
write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
library(xlsx)
install.packages("xlsx")
library(xlsx)
write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
getwd()
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
setwd(PATH)
setwd
getwd()
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
require("tm")
require("SnowballC")
library(slam)
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
library(xlsx)
write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary", append=TRUE)
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tfidf", append=TRUE)
unlink(".RData")
corpus
ls()
rm(list = ls())
ls()
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary", append=TRUE)
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tfidf", append=TRUE)
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary", append=TRUE)
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary")
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
# Word Frequency
dtm <- DocumentTermMatrix(corpus)
# dtms <- removeSparseTerms(dtm, 0.1)    
freq <- colSums(as.matrix(dtm))
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)   
head(freq, 14)   
findFreqTerms(dtm, lowfreq=50)
wf <- data.frame(word=names(freq), freq=freq)   
head(wf)  
# Plot Word Frequencies
library(ggplot2)   
p <- ggplot(subset(wf, freq>2), aes(word, freq))    
p <- p + geom_bar(stat="identity")   
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))   
p
# Wordcloud
library(wordcloud)   
set.seed(142)   
wordcloud(names(freq), freq, min.freq=25)
p
wordcloud(names(freq), freq, min.freq=25)
p
stopwords("english")
tdm
tdm
dtm
corpus
rm(list = ls())
ls()
#############################################
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
# (need more memory) write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary")
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
rm(list = ls())
ls()
#############################################
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
# (need more memory) write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary")
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
#############################################
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
# (need more memory) write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary")
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
#############################################
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
# (need more memory) write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary")
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
# (need more memory) write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary")
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
# (need more memory) write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary")
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
# (need more memory) write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary")
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
# COSINE SIMILARITY
PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity"
CORPUS_TEST_PATH = "C:/Users/Tifani/Documents/GitHub/Document-Similarity/Document Similarity/corpus/test"
setwd(PATH)
for (package in c('tm', 'SnowballC', 'slam', 'xlsx')) {
    if (!require(package, character.only=T, quietly=T)) {
        install.packages(package)
        library(package, character.only=T)
    }
}
corpus <- Corpus(DirSource(CORPUS_TEST_PATH))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
tdm.tf <- TermDocumentMatrix(corpus)
tdm.bin <- weightBin(tdm.tf)
tdm.tfidf <- weightTfIdf(tdm.tf, normalize = TRUE)
cosine.dist.bin <- crossprod_simple_triplet_matrix(tdm.bin)/(sqrt(col_sums(tdm.bin^2) %*% t(col_sums(tdm.bin^2))))
cosine.dist.tf <- crossprod_simple_triplet_matrix(tdm.tf)/(sqrt(col_sums(tdm.tf^2) %*% t(col_sums(tdm.tf^2))))
cosine.dist.tfidf <- crossprod_simple_triplet_matrix(tdm.tfidf)/(sqrt(col_sums(tdm.tfidf^2) %*% t(col_sums(tdm.tfidf^2))))
m.vector.space <- as.matrix(tdm.tf)
m.bin <- as.matrix(cosine.dist.bin)   
m.tf <- as.matrix(cosine.dist.tf)   
m.tfidf <- as.matrix(cosine.dist.tfidf)
# (need more memory) write.xlsx(m.vector.space, file="doc_sim.xlsx", sheetName="vector_space")
write.xlsx(m.bin, file="doc_sim.xlsx", sheetName="cosine_binary")
write.xlsx(m.tf, file="doc_sim.xlsx", sheetName="cosine_tf", append=TRUE)
write.xlsx(m.tfidf, file="doc_sim.xlsx", sheetName="cosine_tf-idf", append=TRUE)
q()
